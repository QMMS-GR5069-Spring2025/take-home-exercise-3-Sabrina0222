{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8168b92-abbe-4ab6-bf2a-11485ad25d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Homework #4: model building and tracking -- Yuxi Sun\n",
    "\n",
    "Instructions: For this assignment, weâ€™d like you to use the F1 Datasets we have been using for the class to build any ML model of your choice and track the model for each run using MLflow. Select any of the F1 datasets in AWS S3 to build your model. You are allowed to join multiple datasets.\n",
    "\n",
    "[20 pts] Build any model of your choice with tunable hyperparameters\n",
    "\n",
    "[20 pts] Create an experiment setup where - for each run - you log:\n",
    "\n",
    "the hyperparameters used in the model\n",
    "the model itself\n",
    "every possible metric from the model you chose\n",
    "at least two artifacts (plots, or csv files)\n",
    "[20 pts] Track your MLFlow experiment and run at least 10 experiments with different parameters each\n",
    "\n",
    "[20 pts] Select your best model run and explain why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am going to build a Decision Tree model that predicts the finishing position of the driver as a numeric value via regression.I will be using DecisionTreeRegressor for the regression, and MAE, MSE, R^2 for the metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de7b0032-8927-4258-96d7-f735557a2081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preparattion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ecd1fe-9e2c-43d6-bef5-6547fbd5e7d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 18296\n",
      "Test set size:  7784\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# the S3 path\n",
    "s3_path = \"s3a://columbia-gr5069-main/raw/\"\n",
    "\n",
    "# read the CSV files into spark dataFrames\n",
    "df_races = (spark.read.csv(f\"{s3_path}/races.csv\", header = True))\n",
    "df_results = (spark.read.csv(f\"{s3_path}/results.csv\", header = True))\n",
    "\n",
    "\n",
    "# join results and races tables\n",
    "df_joined = (\n",
    "    df_results.alias(\"res\")\n",
    "    .join(df_races.alias(\"rac\"), F.col(\"res.raceId\") == F.col(\"rac.raceId\"))\n",
    "    .select(\n",
    "        \"res.raceId\",\n",
    "        \"res.driverId\",\n",
    "        \"res.constructorId\",\n",
    "        \"res.grid\",\n",
    "        \"res.positionOrder\", \n",
    "        \"res.laps\",\n",
    "        \"res.milliseconds\",\n",
    "        \"rac.year\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# only keep rows with a positionOrder which is non-null and > 0\n",
    "df_valid = df_joined.filter(\n",
    "    (F.col(\"positionOrder\").isNotNull()) & (F.col(\"positionOrder\") > 0)\n",
    ")\n",
    "\n",
    "# select features and label\n",
    "df_features = df_valid.select(\n",
    "    F.col(\"grid\").cast(FloatType()),\n",
    "    F.col(\"laps\").cast(FloatType()),\n",
    "    F.col(\"milliseconds\").cast(FloatType()),\n",
    "    F.col(\"positionOrder\").cast(FloatType()).alias(\"label\")\n",
    ").fillna(0, subset=[\"grid\", \"laps\", \"milliseconds\"])\n",
    "\n",
    "# split into train/test\n",
    "train_df, test_df = df_features.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"Train set size: {train_df.count()}\")\n",
    "print(f\"Test set size:  {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a6c944-2d2c-4d0a-8295-2384fe565299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Build a Spark ML Pipeline with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5fff570-4427-4bab-b65d-fd619689db23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"grid\", \"laps\", \"milliseconds\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "dt = DecisionTreeRegressor(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e808fa-56be-4c3a-96e9-bb2246671722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set Up an MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f5ae9e-1f02-4265-aafd-abe1f6aca471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/541281381338533', creation_time=1744137922619, experiment_id='541281381338533', last_update_time=1744137922619, lifecycle_stage='active', name='/Users/ys3874@columbia.edu/HW4/f1-decisionTree-exp', tags={'mlflow.experiment.sourceName': '/Users/ys3874@columbia.edu/HW4/f1-decisionTree-exp',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'ys3874@columbia.edu',\n",
       " 'mlflow.ownerId': '6756958367820344'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Users/ys3874@columbia.edu/HW4/f1-decisionTree-exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e1137c4-dfc8-4898-b716-c660d5b6a4ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train & Track Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e45350b-33d8-43b2-8ee3-b479170698ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/08 19:02:04 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "/databricks/python/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2025/04/08 19:02:44 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:03:24 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:04:10 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:04:48 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:05:25 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:06:04 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:06:42 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:07:19 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n",
      "2025/04/08 19:07:56 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MSE: 13.474520365813373\n",
      "Best run ID: b6350355c72440bc95fad2e6b40c7a78\n",
      "Best params: (maxDepth=6, maxBins=64, minInfoGain=0.05)\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.ERROR)\n",
    "\n",
    "# hyperparam values inputed by myself\n",
    "maxDepth_values = [2, 6, 12]\n",
    "maxBins_values = [16, 32, 64]\n",
    "minInfoGain_values = [0.01, 0.05, 0.1]\n",
    "\n",
    "# control to run 10 times\n",
    "param_combinations = [\n",
    "    (2, 16, 0.01),\n",
    "    (2, 32, 0.05),\n",
    "    (2, 64, 0.05),\n",
    "    (6, 16, 0.01),\n",
    "    (6, 32, 0.05),\n",
    "    (6, 32, 0.1),\n",
    "    (6, 64, 0.05),\n",
    "    (12, 32, 0.01),\n",
    "    (12, 32, 0.05),\n",
    "    (12, 64, 0.1)\n",
    "]\n",
    "\n",
    "# some printing parameters\n",
    "best_mse = float(\"inf\")\n",
    "best_run_id = None\n",
    "best_params = None\n",
    "\n",
    "for (max_depth, max_bins, min_info_gain) in param_combinations:\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        # log hyperparams\n",
    "        mlflow.log_param(\"maxDepth\", max_depth)\n",
    "        mlflow.log_param(\"maxBins\", max_bins)\n",
    "        mlflow.log_param(\"minInfoGain\", min_info_gain)\n",
    "        \n",
    "        # create a new pipeline with these hyperparams\n",
    "        current_dt = DecisionTreeRegressor(\n",
    "            labelCol=\"label\",\n",
    "            featuresCol=\"features\",\n",
    "            maxDepth=max_depth,\n",
    "            maxBins=max_bins,\n",
    "            minInfoGain=min_info_gain\n",
    "        )\n",
    "        current_pipeline = Pipeline(stages=[assembler, current_dt])\n",
    "        \n",
    "        # fit the model\n",
    "        model = current_pipeline.fit(train_df)\n",
    "        \n",
    "        # evaluate via test set\n",
    "        predictions = model.transform(test_df)\n",
    "        \n",
    "        # collect predictions\n",
    "        pdf = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "        \n",
    "        # calculate metrics\n",
    "        mse = mean_squared_error(pdf[\"label\"], pdf[\"prediction\"])\n",
    "        mae = mean_absolute_error(pdf[\"label\"], pdf[\"prediction\"])\n",
    "        r2 = r2_score(pdf[\"label\"], pdf[\"prediction\"])\n",
    "        \n",
    "        # log metrics\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        \n",
    "        # create plot: actual vs. predicted finishing position\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(pdf[\"label\"], pdf[\"prediction\"], alpha=0.5)\n",
    "        ax.set_xlabel(\"Actual Finishing Position\")\n",
    "        ax.set_ylabel(\"Predicted Finishing Position\")\n",
    "        ax.set_title(\"Actual vs. Predicted Finishing Position\")\n",
    "        \n",
    "        # save plot\n",
    "        plot_path = f\"scatter_{run_id}.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # log artifact\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        \n",
    "        # log predictions in a CSV file\n",
    "        csv_path = f\"predictions_{run_id}.csv\"\n",
    "        pdf.to_csv(csv_path, index=False)\n",
    "        mlflow.log_artifact(csv_path)\n",
    "        \n",
    "        # log the Spark model\n",
    "        mlflow.spark.log_model(model, artifact_path=\"decision-tree-regressor\")\n",
    "        \n",
    "        # clean up\n",
    "        os.remove(plot_path)\n",
    "        os.remove(csv_path)\n",
    "        \n",
    "        # select best model based on MSE\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_run_id = run_id\n",
    "            best_params = (max_depth, max_bins, min_info_gain)\n",
    "\n",
    "print(f\"Best MSE: {best_mse}\")\n",
    "print(f\"Best run ID: {best_run_id}\")\n",
    "print(f\"Best params: (maxDepth={best_params[0]}, maxBins={best_params[1]}, minInfoGain={best_params[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c24b3f7-82cf-45b7-9619-79e0dfc31be3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As can be seen from the results, the combination \"maxDepth=6, maxBins=64, minInfoGain=0.05\" obtains the lowest MSE, which I consider it as the best model run. \n",
    "\n",
    "For max depth, the best parameter is 6, among 2,6,12. The depth = 6 is deep enough to capture nuanced relationships, while 2 is too shallower and 12 is too deep that may face overfitting.\n",
    "\n",
    "For max bins, the best parameter is 64, among 16, 32, 64. The bins = 64 gives the model finer-grained split thresholds that helps the tree isolate patterns relevant to finishing position without causing significant overfitting. \n",
    "\n",
    "For minimun information gain, the best parameter is 0.05, among 0.01,0.05,0.1. The minInfoGain = 0.05 allows the model to require each split to be at least 5% improvement, which avoids more noise comparing to 0.01.\n",
    "\n",
    "Overall, with maxDepth = 6 and maxBins = 64, the model is capable of finding proper splits while avoid overfitting and underfitting by setting the mininum information gain to be 5%."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "HW4_5069_draft",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
